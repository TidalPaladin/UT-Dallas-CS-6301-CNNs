{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 <a name=\"introduction\"></a>\n",
    "\n",
    "## 26 <a name=\"26\"></a>\n",
    "\n",
    "We have a residual layer with the following reverse graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $\\frac{\\partial e}{\\partial x}$ we will need\n",
    "to apply the chain rule through $f(x)$ and sum on the\n",
    "residual merge. This gives\n",
    "\n",
    "$$\n",
    "\\frac{\\partial e}{\\partial x} = \n",
    "    \\frac{\\partial f}{\\partial x}\n",
    "    \\cdot\n",
    "    \\frac{\\partial e}{\\partial y} \n",
    "$$\n",
    "## 27 <a name=\"27\"></a>\n",
    "\n",
    "## 28 <a name=\"28\"></a>\n",
    "\n",
    "# Problem 3 <a name=\"p3\"></a>\n",
    "The Tiny ImageNet dataset can be downloaded \n",
    "[here](http://cs231n.stanford.edu/tiny-imagenet-200.zip)\n",
    "Extract the zip onto a fast disk drive. First we will set up the\n",
    "python environment and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ProgbarLogger\n",
    "from tensorflow.losses import sparse_softmax_cross_entropy as softmax_xent\n",
    "from tensorflow.data import TFRecordDataset\n",
    "from tensorflow.data.experimental import TFRecordWriter\n",
    "#from tensorflow.data.experimental import naive_shard\n",
    "\n",
    "# For TFRecord demo\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "# Train on secondary GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the directory\n",
    "structure of the dataset, we see that there are subdirectory for\n",
    "training, validating, and testing. The training set contains\n",
    "200 classes where images of a class are grouped by directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing <a name=\"introduction\"></a>\n",
    "\n",
    "We can import the training set with preprocessing as follows\n",
    "(documentation available \n",
    "[here](https://keras.io/preprocessing/image/).)\n",
    "\n",
    "We will use the `ImageDataGenerator`. This works will on the\n",
    "training set by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Constants(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "# Constants for important filepaths\n",
    "DATASET_ROOT = '/home/tidal/tiny-imagenet-200/tiny-imagenet-200'\n",
    "DIRS = {\n",
    "    'root' : '/',\n",
    "    'tfrecord' :  'tfrecords',\n",
    "    'train' : 'train',\n",
    "    'test' :  'test',\n",
    "    'val' : 'val',\n",
    "    'checkpoint' : 'checkpoints'\n",
    "}\n",
    "DIRS = { k : os.path.join(DATASET_ROOT, v) for k, v in DIRS.items() }\n",
    "DIRS = Constants(DIRS)\n",
    "\n",
    "# Input shape, batching, and data type\n",
    "inputs = tf.keras.layers.Input(\n",
    "    shape=[3, 64, 64],\n",
    "    name='input',\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "# Ground truth sparse labels\n",
    "labels = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=[None, 1],\n",
    "    name='label'\n",
    ")\n",
    "\n",
    "# Training parameters\n",
    "TRAIN = {\n",
    "    'num_classes' : 200,\n",
    "    'batch_size' : 128,\n",
    "    'shuffle' : 5000,\n",
    "    'num_epochs' : 72,\n",
    "    'momentum' : 0.9,\n",
    "    'regularizer_scale' : 0.1,\n",
    "    'lr_initial' : 0.01,\n",
    "    'lr_scale' : 0.1,\n",
    "    'lr_epoch' : 64,\n",
    "    'val_split' : 0.2,\n",
    "    'lr_staircase' : True,\n",
    "    'max_checkpoint' : 5,\n",
    "    'checkpoint_fmt' : 'resnet_{epoch:02d}.hdf5'\n",
    "}\n",
    "TRAIN = Constants(TRAIN)\n",
    "\n",
    "# Shard generation parameters\n",
    "TFRECORD = {\n",
    "    'file_format' : os.path.join(DIRS.tfrecord, 'tin_train_%i.tfrecord'),\n",
    "    'train_glob' : os.path.join(DIRS.tfrecord, '.*_train_.*tfrecord'),\n",
    "    'val_glob' : os.path.join(DIRS.tfrecord, '.*_val_.*tfrecord'),\n",
    "    'num_shards' : 30\n",
    "}\n",
    "TFRECORD = Constants(TFRECORD)\n",
    "\n",
    "CONST = Constants({'train' : TRAIN, 'tfrecord' : TFRECORD, 'dirs' : DIRS})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing to a `Dataset`\n",
    "\n",
    "Now that we have defined constants, we can begin reading training data in\n",
    "preparation for writing sharded `TFRecord` files. Keras provides the\n",
    "`ImageDataGenerator` which accepts formatting and preprocessing information\n",
    "as arguments and returns an `ImageDataGenerator` object. One method of this\n",
    "returned object is the `flow_from_directory` method which automatically\n",
    "interprets the file structure of the training set and returns an iterator\n",
    "over training files.\n",
    "\n",
    "First we create the `ImageDataGenerator`. We will use the following args\n",
    " * `samplewise_center=True` - Normalize to zero mean\n",
    " * `samplewise_std_normalization=True` - Normalize to unit variance\n",
    " * `horizontal_flip=True` - Flip images\n",
    " * `data_format=True` - Generator should yield images with channels on axis 0\n",
    " * `rescale=1./255` - Rescale 8 bit images to a float on [0, 1]\n",
    "\n",
    "**Note** that no shuffling was used - according to the documentation,\n",
    "shuffling should be done after any sharding operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a seprate graph to handle TFRecord writing\n",
    "shard_graph = tf.Graph()\n",
    "\n",
    "# Define a data generator with preprocessing \n",
    "# Includes a ratio to reserve for validation\n",
    "with shard_graph.as_default():\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            samplewise_center=True,\n",
    "            samplewise_std_normalization=True,\n",
    "            horizontal_flip=True,\n",
    "            data_format='channels_first',\n",
    "            rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next create a wrapper function for `flow_from_directory`. As stated\n",
    "earlier, this method will return an iterator over the dataset. \n",
    "The purpose of using a wrapper function is to maintain code cleanliness\n",
    "when the callable `flow_from_directory` will need to be passed to other\n",
    "functions (will be more clear below). The arguments are as follows\n",
    "\n",
    " * `DIRS.train` - The directory to flow from\n",
    " * `target_size` - Shape of outputs from iterator\n",
    " * `batch_size` - Batching\n",
    " * `class_mode='sparse'` - Give an integer for label class, rather than a one\n",
    " hot vector\n",
    "\n",
    " **Note:** When using `class_mode='sparse'`, loss functions should be sparse\n",
    " as well, ie `sparse_softmax_cross_entropy`. By default `categorical` will be\n",
    " used, which yields the full one-hot label vector. In such cases, do **not**\n",
    " use a sparse loss function. Ambiguous errors will be produced regarding the\n",
    " dimentionality of inputs to the loss function when training begins.\n",
    "\n",
    "We can also call the generator method to see a message on the number of\n",
    "examples and classes found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap flow_from_directory in simple callable\n",
    "def generator():\n",
    "\n",
    "    return train_datagen.flow_from_directory(\n",
    "            DIRS.train,\n",
    "            target_size=inputs.shape[2:4].as_list(),\n",
    "            batch_size=1,\n",
    "            class_mode='sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a function `generator()` that returns an iterator over the\n",
    "training dataset. The iterator yields correctly batched groups of training\n",
    "images / labels, with preprocessing already applied. Finally, we will\n",
    "use this generator to produce a `Dataset` object. Note that there are \n",
    "other approaches where the generator can be used without this wrapping.\n",
    "\n",
    "After wrapping we can verify the shapes and types of the `Dataset` are\n",
    "as expected (with batching on the first dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with shard_graph.as_default():\n",
    "    output_types = inputs.dtype, labels.dtype\n",
    "    output_shapes = inputs.shape, labels.shape\n",
    "    ds_train = tf.data.Dataset.from_generator(\n",
    "            generator,\n",
    "            output_types=output_types,\n",
    "            output_shapes=output_shapes)\n",
    "    ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing `.tfrecord` Files\n",
    "\n",
    "Finally, we can produce `.tfrecord` files for our `Dataset`.\n",
    "\n",
    "THIS JUST BUILDS THE GRAPH, NOTHING RUNS YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with shard_graph.as_default():\n",
    "    for current_shard in range(0,TFRECORD.num_shards):\n",
    "        filepath = TFRECORD.file_format % current_shard\n",
    "        clear_output(wait=True)\n",
    "        #print('Processing shard %i / %i' % (current_shard+1, TFRECORD.num_shards))\n",
    "        #print('Path: %s' % filepath)\n",
    "\n",
    "        writer = TFRecordWriter(filepath)\n",
    "\n",
    "        # Create a Dataset with 1/num_shards elements\n",
    "        shard = ds_train.shard(TFRECORD.num_shards, current_shard)\n",
    "\n",
    "        # New way, wouldn't work with my tensorflow (no filter_for_shard)\n",
    "        # shard_func = filter_for_shard(current_shard, TFRECORD.num_shards)\n",
    "        # shard = ds_train.apply(shard_func)\n",
    "\n",
    "        def serialize_tensor_tuple(img, label):\n",
    "            # Serialize two separate tensors\n",
    "            img_s = tf.serialize_tensor(img)\n",
    "            label_s = tf.serialize_tensor(label)\n",
    "            return tf.string_join([img_s, label_s])\n",
    "\n",
    "        shard = shard.map(serialize_tensor_tuple)\n",
    "        writer.write(shard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with shard_graph.as_default():\n",
    "    session = tf.Session()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to extract an example from a record file\n",
    "def parse_record(example_proto, clip=False):\n",
    "\n",
    "    # The features contained in the written TFRecord\n",
    "    tfrecord_read_features = {\n",
    "           'image': tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "           'label': tf.FixedLenFeature(shape=[], dtype=tf.string)\n",
    "    }\n",
    "\n",
    "    example = tf.parse_single_example(example_proto, tfrecord_read_features)\n",
    "    img = tf.decode_raw(example['image'], tf.float32)\n",
    "    label = tf.decode_raw(example['label'], tf.float32)\n",
    "\n",
    "    img = tf.reshape(img, inputs.shape[1:4])\n",
    "    label = tf.reshape(label, (1,))\n",
    "    label = tf.squeeze(label)\n",
    "    label = tf.cast(label, int32)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "# Construct a TFRecordDataset mapped over all shards\n",
    "filenames = tf.data.Dataset.list_files(TFRECORD.train_glob)\n",
    "ds_train = tf.data.TFRecordDataset(filenames).map(parse_record)\n",
    "ds_train = ds_train.shuffle(TRAIN.shuffle)\n",
    "ds_train = ds_train.batch(TRAIN.batch_size)\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shards():\n",
    "\n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    dataset_iterator = generator()\n",
    "    print('Writing %i shards...' % TFRECORD.num_shards)\n",
    "\n",
    "    for shard, batch in enumerate(dataset_iterator):\n",
    "        if shard > TFRECORD.num_shards: break\n",
    "        filepath = TFRECORD.file_format % shard\n",
    "        print('  |-- %s' % os.path.basename(filepath))\n",
    "\n",
    "        with tf.python_io.TFRecordWriter(filepath) as writer:\n",
    "\n",
    "            for img, label in zip(batch[0], batch[1]):\n",
    "\n",
    "                feature = {\n",
    "                    'image': _bytes_feature(img.tostring()),\n",
    "                    'label': _bytes_feature(label.tostring()),\n",
    "                }\n",
    "                \n",
    "                features=tf.train.Features(feature=feature)\n",
    "                example = tf.train.Example(features=features)\n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "make_shards()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for the validation and testing sets the `ImageDataGenerator`\n",
    "expects directory for each label. We must manually fix labels\n",
    "\n",
    "# Problem 4 <a name=\"p4\"></a>\n",
    "Understood\n",
    "\n",
    "# Problem 5 - Modifying Resnet <a name=\"p5\"></a>\n",
    "\n",
    "We can construct Resnet using a subclassed approach. This involves\n",
    "creating modular blocks of layers that can be reused as needed, thus\n",
    "increasing code reuseability and ease of maintainance. \n",
    "\n",
    "Specifically, we subclass `tf.keras.Model` and implement the methods\n",
    "`__init__()` and `call()`. Our choice of `__init__()` method will define\n",
    "the the types of layers in this block, but says nothing about how they\n",
    "are connected. In the `call()` method we will define the connections\n",
    "between layers. This method takes an input as a parameter and returns\n",
    "an ouput that represents the feature maps after a forward pass through\n",
    "all layers in the block.\n",
    "\n",
    "## Basic Block <a name=\"basic\"></a>\n",
    "\n",
    "First we will define the fundamental CNN style 2D convolution block\n",
    "of Resnet, ie\n",
    "\n",
    "Note that the number of filters and the kernel size are \n",
    "parameterized, and that parameter packs `*args, **kwargs`\n",
    "are forwarded to the convolution layer. This is important\n",
    "as it enables the reuse of this model for the various\n",
    "types of convolutions that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class ResnetBasic(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, filters, kernel_size, strides=(1,1), *args, **kwargs):\n",
    "        super(ResnetBasic, self).__init__(*args, **kwargs)\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv2d = layers.Conv2D(\n",
    "                filters,\n",
    "                kernel_size,\n",
    "                padding='same',\n",
    "                data_format='channels_last',\n",
    "                activation=None,\n",
    "                use_bias=False,\n",
    "                strides=strides)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = self.batch_norm(inputs, **kwargs)\n",
    "        x = self.relu(x, **kwargs)\n",
    "        return self.conv2d(x, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Bottleneck\n",
    "\n",
    "Recognizing this, we can define a bottleneck layer. Again,\n",
    "the number of input feature maps is parameterized. \n",
    "We no longer parameterize the kernel dimensions, as these\n",
    "are intrinsic to this type of block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, Ni, *args, **kwargs):\n",
    "        super(Bottleneck, self).__init__(*args, **kwargs)\n",
    "\n",
    "        # Three residual convolution blocks\n",
    "        kernels = [(1, 1), (3, 3), (1, 1)]\n",
    "        feature_maps = [Ni // 4, Ni // 4, Ni]\n",
    "        self.residual_filters = [\n",
    "            ResnetBasic(N, K) \n",
    "            for N, K in zip(feature_maps, kernels) \n",
    "        ] \n",
    "\n",
    "        # Merge operation\n",
    "        self.merge = layers.Add()\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "\n",
    "        # Residual forward pass\n",
    "        res = inputs\n",
    "        for res_layer in self.residual_filters:\n",
    "            res = res_layer(res, **kwargs)\n",
    "\n",
    "        # Combine residual pass with identity\n",
    "        return self.merge([inputs, res], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Bottleneck\n",
    "\n",
    "We can define the special bottleneck layer by subclassing\n",
    "the `Bottleneck` class as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialBottleneck(Bottleneck):\n",
    "\n",
    "    def __init__(self, Ni, *args, **kwargs):\n",
    "\n",
    "        # Layers that also appear in standard bottleneck\n",
    "        super(SpecialBottleneck, self).__init__(Ni, *args, **kwargs)\n",
    "\n",
    "        # Add convolution layer along main path\n",
    "        self.main = layers.Conv2D(\n",
    "                Ni,\n",
    "                (1, 1),\n",
    "                padding='same',\n",
    "                data_format='channels_last',\n",
    "                activation=None,\n",
    "                use_bias=False)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "\n",
    "        # Residual forward pass\n",
    "        res = inputs\n",
    "        for res_layer in self.residual_filters:\n",
    "            res = res_layer(res, **kwargs)\n",
    "\n",
    "        # Convolution on main forward pass\n",
    "        main = self.main(inputs, **kwargs)\n",
    "\n",
    "        # Merge residual and main\n",
    "        return self.merge([main, res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "\n",
    "Next we need to define the downsampling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, Ni, *args, **kwargs):\n",
    "        super(Downsample, self).__init__(*args, **kwargs)\n",
    "\n",
    "        # Three residual convolution blocks\n",
    "        kernels = [(1, 1), (3, 3), (1, 1)]\n",
    "        strides = [(2, 2), (1, 1), (1, 1)]\n",
    "        feature_maps = [Ni // 2, Ni // 2, 2*Ni]\n",
    "\n",
    "        self.residual_filters = [\n",
    "            ResnetBasic(N, K, strides=S) \n",
    "            for N, K, S in zip(feature_maps, kernels, strides) \n",
    "        ] \n",
    "\n",
    "        # Convolution on main path\n",
    "        self.main = ResnetBasic(2*Ni, (1,1), strides=(2,2))\n",
    "\n",
    "        # Merge operation for residual and main\n",
    "        self.merge = layers.Add()\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "\n",
    "        # Residual forward pass\n",
    "        res = inputs\n",
    "        for res_layer in self.residual_filters:\n",
    "            res = res_layer(res,**kwargs)\n",
    "\n",
    "        # Main forward pass\n",
    "        main = self.main(inputs, **kwargs)\n",
    "\n",
    "        # Merge residual and main\n",
    "        return self.merge([main, res])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "\n",
    "Finally, we can assemble these blocks into the final model. Note\n",
    "that the tail and other simple layers are defined within the \n",
    "Resnet model class, rather than being subclassed as we did\n",
    "with the other building blocks. This choice came down to the\n",
    "simplicity of tail and other non-subclassed layers.\n",
    "\n",
    "Also worth noting is the use of `layers.GlobalAveragePooling2D`. There\n",
    "is no `keras.layers.reduce_mean()` layer, but this operation represents\n",
    "global average pooling so we simply choose the correct layer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, classes, filters, levels, *args, **kwargs):\n",
    "        super(Resnet, self).__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "        # Lists to hold various layers\n",
    "        self.blocks = list()\n",
    "\n",
    "        # Tail\n",
    "        self.tail = layers.Conv2D(\n",
    "                filters,\n",
    "                (3, 3),\n",
    "                padding='same',\n",
    "                data_format='channels_last',\n",
    "                use_bias=False,\n",
    "                name='tail')\n",
    "\n",
    "        # Special bottleneck layer with convolution on main path\n",
    "        self.level_0_special = SpecialBottleneck(filters)\n",
    "\n",
    "        # Loop through levels and their parameterized repeat counts\n",
    "        for level, repeats in enumerate(levels):\n",
    "            for block in range(repeats):\n",
    "                # Append a bottleneck block for each repeat\n",
    "                name = 'bottleneck_%i_%i' % (level, block)\n",
    "                layer = Bottleneck(filters, name=name)\n",
    "                self.blocks.append(layer)\n",
    "\n",
    "            # Downsample and double feature maps at end of level\n",
    "            name = 'downsample_%i' % (level)\n",
    "            layer = Downsample(filters, name=name)\n",
    "            self.blocks.append(layer) \n",
    "            filters *= 2\n",
    "\n",
    "        # encoder - level 2 special block x1\n",
    "        # input:  256 x   8 x 8\n",
    "        # output: 256 x   8 x 8\n",
    "        self.level2_batch_norm = layers.BatchNormalization()\n",
    "        self.level2_relu = layers.ReLU()\n",
    "\n",
    "        # Decoder - global average pool and fully connected\n",
    "        self.global_avg = layers.GlobalAveragePooling2D(\n",
    "                data_format='channels_last')\n",
    "        self.dense = layers.Dense(classes, \n",
    "                use_bias=True)\n",
    "\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = self.tail(inputs, **kwargs)\n",
    "        x = self.level_0_special(x)\n",
    "\n",
    "        # Loop over layers by level\n",
    "        for layer in self.blocks:\n",
    "            x = layer(x, **kwargs)\n",
    "\n",
    "        # Finish up specials in level 2\n",
    "        x = self.level2_batch_norm(x, **kwargs)\n",
    "        x = self.level2_relu(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.global_avg(x)\n",
    "        return self.dense(x, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model\n",
    "\n",
    "Now that we have defined a subclassed model, we need to\n",
    "incorproate it into a training / testing environment. This is\n",
    "where the beauty of the subclassed approach comes in. \n",
    "In our case\n",
    "we want construct Resnet modified for Tiny Imagenet, where the\n",
    "modifications are as follows:\n",
    "\n",
    " * Third level of residual blocks + downsampling\n",
    " * Full and half width versions\n",
    "\n",
    "Our Resnet class accepts an interable of integers to define the\n",
    "number of repeats at each level. As such, we need only add an\n",
    "integer for the number of repeats at level 3 to our constructor call.\n",
    "Similarly, we can scale the number of feature maps as needed to adjust\n",
    "width.\n",
    "\n",
    "Lastly we will provide the number of classes in Tiny Imagenet, ie $200$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another level\n",
    "standard_levels = [4, 6, 3]\n",
    "new_level_count = 2\n",
    "modified_levels = standard_levels + [new_level_count]\n",
    "\n",
    "# Define full and half width feature map count\n",
    "full_width = 64\n",
    "half_width = full_width / 2\n",
    "\n",
    "# Tiny Imagenet properties\n",
    "\n",
    "\n",
    "model = Resnet(TRAIN.num_classes, full_width, modified_levels)\n",
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `model` returned by our class constructor is callable.\n",
    "Thus our forward pass mapping inputs to outputs is invoked by\n",
    "\"calling\" `model` on the inputs and storing the returned outputs.\n",
    "Note that a call on model is simply calling the \n",
    "`Resnet.call()` method we wrote earlier. More on this when we get\n",
    "to training.\n",
    "\n",
    "Finally, we can build the model for the appropriate input shape\n",
    "and get a summary of the included layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6 - Saving Validation\n",
    "\n",
    "Now we can construct a training loop with the following additional\n",
    "features\n",
    "\n",
    " * Saving validation loss/accuracy on a per epoch basis\n",
    " * Checkpointing after each epoch with ability to restore from \n",
    "   checkpoint\n",
    "\n",
    "First we will define training hyperparameters to be used later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Metrics\n",
    "\n",
    "Next we define an accuracy and loss metric, as well as an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# loss\n",
    "loss = softmax_xent\n",
    "#loss = 'categorical_crossentropy'\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpointing and whatnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(DIRS.checkpoint, TRAIN.checkpoint_fmt)\n",
    "callbacks = [ \n",
    "        ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True),\n",
    "        #ProgbarLogger(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [No files matched pattern: /home/tidal/tiny-imagenet-200/tiny-imagenet-200/tfrecords/.*_train_.*tfrecord]\n\t [[node list_files_5/assert_not_empty/Assert (defined at <ipython-input-33-57a02fee8892>:3)  = Assert[T=[DT_STRING], summarize=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](list_files_5/match_not_empty/_1327, list_files_5/message)]]\n\t [[{{node list_files_5/assert_not_empty/Assert/_1332}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_17_list_files_5/assert_not_empty/Assert\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'list_files_5/assert_not_empty/Assert', defined at:\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-57a02fee8892>\", line 3, in <module>\n    filenames = tf.data.Dataset.list_files(TFRECORD.train_glob)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 698, in list_files\n    condition, [message], summarize=1, name=\"assert_not_empty\")\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py\", line 189, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 159, in Assert\n    return gen_logging_ops._assert(condition, data, summarize, name=\"Assert\")\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 52, in _assert\n    name=name)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): assertion failed: [No files matched pattern: /home/tidal/tiny-imagenet-200/tiny-imagenet-200/tfrecords/.*_train_.*tfrecord]\n\t [[node list_files_5/assert_not_empty/Assert (defined at <ipython-input-33-57a02fee8892>:3)  = Assert[T=[DT_STRING], summarize=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](list_files_5/match_not_empty/_1327, list_files_5/message)]]\n\t [[{{node list_files_5/assert_not_empty/Assert/_1332}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_17_list_files_5/assert_not_empty/Assert\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [No files matched pattern: /home/tidal/tiny-imagenet-200/tiny-imagenet-200/tfrecords/.*_train_.*tfrecord]\n\t [[{{node list_files_5/assert_not_empty/Assert}} = Assert[T=[DT_STRING], summarize=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](list_files_5/match_not_empty/_1327, list_files_5/message)]]\n\t [[{{node list_files_5/assert_not_empty/Assert/_1332}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_17_list_files_5/assert_not_empty/Assert\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-d4887523ac87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#callbacks=callbacks,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         epochs=TRAIN.num_epochs)\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    945\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_iterator_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m           \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [No files matched pattern: /home/tidal/tiny-imagenet-200/tiny-imagenet-200/tfrecords/.*_train_.*tfrecord]\n\t [[node list_files_5/assert_not_empty/Assert (defined at <ipython-input-33-57a02fee8892>:3)  = Assert[T=[DT_STRING], summarize=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](list_files_5/match_not_empty/_1327, list_files_5/message)]]\n\t [[{{node list_files_5/assert_not_empty/Assert/_1332}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_17_list_files_5/assert_not_empty/Assert\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'list_files_5/assert_not_empty/Assert', defined at:\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/tidal/.local/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/tidal/.local/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-57a02fee8892>\", line 3, in <module>\n    filenames = tf.data.Dataset.list_files(TFRECORD.train_glob)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 698, in list_files\n    condition, [message], summarize=1, name=\"assert_not_empty\")\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py\", line 189, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 159, in Assert\n    return gen_logging_ops._assert(condition, data, summarize, name=\"Assert\")\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 52, in _assert\n    name=name)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): assertion failed: [No files matched pattern: /home/tidal/tiny-imagenet-200/tiny-imagenet-200/tfrecords/.*_train_.*tfrecord]\n\t [[node list_files_5/assert_not_empty/Assert (defined at <ipython-input-33-57a02fee8892>:3)  = Assert[T=[DT_STRING], summarize=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](list_files_5/match_not_empty/_1327, list_files_5/message)]]\n\t [[{{node list_files_5/assert_not_empty/Assert/_1332}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_17_list_files_5/assert_not_empty/Assert\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "step_size = 100000 * TFRECORD.num_shards // TRAIN.batch_size\n",
    "model.fit(\n",
    "        ds_train,\n",
    "        #callbacks=callbacks,\n",
    "        steps_per_epoch=step_size,\n",
    "        epochs=TRAIN.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x, y in ds_train.take(1):\n",
    "    #print(y.shape)\n",
    "    #y.shape\n",
    "steps_per_epoch\n",
    "128*72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "497 ops no flops stats due to incomplete shapes.\n",
      "497 ops no flops stats due to incomplete shapes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated FLOP 6312804\n",
      "name: \"_TFProfRoot\"\n",
      "total_definition_count: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flops = tf.profiler.profile(options = tf.profiler.ProfileOptionBuilder.float_operation())\n",
    "mem = tf.profiler.profile(options = tf.profiler.ProfileOptionBuilder.time_and_memory())\n",
    "if flops is not None:\n",
    "    print('Calculated FLOP', flops.total_float_ops)\n",
    "if mem is not None:\n",
    "    print(mem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
